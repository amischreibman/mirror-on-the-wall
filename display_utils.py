import time
import cv2
import sys
import random
from screeninfo import get_monitors
import numpy as np
import json
import os
from datetime import datetime
from PIL import Image, ImageDraw, ImageFont
from bidi.algorithm import get_display
from text_renderer import TextRenderer
from transition_manager import TransitionManager
from prompt_generator import PromptGenerator
from data_loader import DataLoader


class DisplayManager:
    def __init__(self, window_name='Mirror on the Wall'):
        self.window_name = window_name
        self.screen_width = 0
        self.screen_height = 0
        self._setup_screen_dimensions()
        self.show_json_overlay = False
        self.last_json_data = None
        self.frame_count = 0
        self.text_positions = {}
        self.show_grid = False
        self.grid_cols = 4
        self.grid_rows = 4
        self.occupied_cells = set()
        self.cell_last_used = {}
        self.target_mode = "visual"  # ××¦×‘ ×™×¢×“ ×œ××¢×‘×¨
        self.scene_transition = False  # ×”×× ×–×” ××¢×‘×¨ ×¡×¦× ×”
        self.show_timer = False
        self.show_info = False
        self.start_time = time.time()
        self.current_active_persons = []  # ×¨×©×™××ª ×× ×©×™× ×¤×¢×™×œ×™× × ×•×›×—×™×ª

        # ×”×•×¡×¤×ª ××©×ª× ×™× ×œ×××’×¨ ×”×©× ×™
        self.display_mode = "visual"  # "visual" ××• "behavioral" ××• "prompt"
        self.behavioral_text_positions = {}
        self.behavioral_occupied_cells = set()
        self.behavioral_cell_last_used = {}
        self.mode_transition_time = None
        self.transition_duration = 2.0  # ×©× ×™×•×ª ×œ××¢×‘×¨

        # ××¢×‘×¨ ×”×“×¨×’×ª×™
        self.in_transition = False
        self.transition_stage = 0  # ×©×œ×‘ ×‘××¢×‘×¨
        self.texts_to_fade_out = []  # ×¨×©×™××ª ×˜×§×¡×˜×™× ×œ×”×¢×œ××”
        self.texts_to_fade_in = []  # ×¨×©×™××ª ×˜×§×¡×˜×™× ×œ×”×•×¤×¢×”
        self.last_transition_step_time = 0

        # ××—×–×•×¨ ×˜×§×¡×˜×™× ×”×ª× ×”×’×•×ª×™×™×
        self.behavioral_cycle_enabled = True
        self.last_behavioral_text_add = 0
        self.behavioral_add_interval = 0.3  # ××”×™×¨ ×™×•×ª×¨ - 0.3 ×©× ×™×•×ª
        self.behavioral_texts_pool = []  # ×××’×¨ ×”×˜×§×¡×˜×™× ×œ××—×–×•×¨
        self.behavioral_pool_index = 0  # ××™× ×“×§×¡ × ×•×›×—×™ ×‘×××’×¨
        self.min_active_behavioral_texts = 10  # ××™× ×™××•× ×˜×§×¡×˜×™× ×¤×¢×™×œ×™×
        self.max_active_behavioral_texts = 10  # ××§×¡×™××•× ×˜×§×¡×˜×™× ×¤×¢×™×œ×™×

        # ×’×™×©×” ×™×©×™×¨×” ×œ× ×ª×•× ×™× ×”×ª× ×”×’×•×ª×™×™×
        self.behavioral_data_saver_ref = None

        # ××©×ª× ×™× ×—×“×©×™× ×œ×˜×™×™××¨ ××•×˜×•××˜×™ ×•××¦×‘ ×¤×¨×•××¤×˜
        self.auto_mode_timer = time.time()  # ×˜×™×™××¨ ×œ××¢×‘×¨ ××•×˜×•××˜×™
        # ×–×× ×™× ×©×•× ×™× ×œ×›×œ ××¦×‘ - ××¢×•×“×›× ×™× ×œ×¡×”"×› 60 ×©× ×™×•×ª
        self.visual_duration = 30.0  # ×›××•×ª ×©× ×™×•×ª ×œ××¦×‘ ×—×–×•×ª×™ (×™×¨×•×§)
        self.behavioral_duration = 20.0  #  ×›××•×ª ×©× ×™×•×ª ×œ××¦×‘ ×”×ª× ×”×’×•×ª×™ (×œ×‘×Ÿ)
        self.prompt_duration = 20.0  # ×›××•×ª ×©× ×™×•×ª ×œ××¦×‘ ×¤×¨×•××¤×˜
        self.prompt_text = ""  # ×”×˜×§×¡×˜ ×©×œ ×”×¤×¨×•××¤×˜
        self.prompt_display_index = 0  # ××™× ×“×§×¡ ×œ××¤×§×˜ ×”×§×œ×“×”
        self.prompt_last_char_time = 0  # ×–××Ÿ ××—×¨×•×Ÿ ×©×”×•×¡×¤× ×• ×ª×•
        self.prompt_generated = False  # ×”×× ×”×¤×¨×•××¤×˜ ×›×‘×¨ × ×•×¦×¨
        self.visual_data_path = None  # × ×ª×™×‘ ×œ× ×ª×•× ×™× ×—×–×•×ª×™×™×
        self.behavioral_data_path = None  # × ×ª×™×‘ ×œ× ×ª×•× ×™× ×”×ª× ×”×’×•×ª×™×™×
        self.all_behavioral_added = False  # ×”×× ×›×œ ×”××©×¤×˜×™× ×”×•×¡×¤×•
        self.prompt_transition_time = None  # ×–××Ÿ ×”××¢×‘×¨ ×œ×¤×¨×•××¤×˜

        # ××©×ª× ×™× ×œ××¢×§×‘ ××—×¨×™ ××¦×‘ ×”×¤×¨×•××¤×˜ ×›×©×™×© ×× ×©×™×
        self.prompt_active = False  # ×”×× ×”×¤×¨×•××¤×˜ ×¤×¢×™×œ ×›×¨×’×¢
        self.prompt_fade_out_start = None  # ×–××Ÿ ×”×ª×—×œ×ª fade out
        self.prompt_fade_out_duration = 3.0  # ××©×š fade out ×‘×©× ×™×•×ª
        self.prompt_fade_in_start = None  # ×–××Ÿ ×”×ª×—×œ×ª fade in
        self.prompt_fade_in_duration = 0.5  # ××©×š fade in ×‘×©× ×™×•×ª
        self.prompt_opacity = 0.0  # ×©×§×™×¤×•×ª × ×•×›×—×™×ª ×©×œ ×”×¤×¨×•××¤×˜ (0-1)
        self.last_people_count = 0  # ××¡×¤×¨ ×”×× ×©×™× ×”××—×¨×•×Ÿ ×©×–×•×”×”
        self.people_positions = []  # ××™×§×•××™ ×”×× ×©×™× (×™××™×Ÿ, ×©×××œ, ××¨×›×– ×•×›×•')

        # ×–×× ×™× ××•×—×œ×˜×™× ××ª×—×™×œ×ª ×”×™×™×©×•×
        self.app_start_time = time.time()  # ×–××Ÿ ×”×ª×—×œ×ª ×”×™×™×©×•×
        self.visual_start_time = 0  # ×©× ×™×” 0
        self.visual_fadeout_start_time = 25  # ×©× ×™×” 25 - ×ª×—×™×œ×ª fade out
        self.visual_fadeout_started = False
        self.behavioral_start_time = 30  # ×©× ×™×” 30
        self.prompt_start_time = 60  # ×©× ×™×” 60 (×“×§×”)
        # ××™×ª×—×•×œ ××©×ª× ×™× ×œ××¢×§×‘ ××—×¨×™ ××¦×‘ behavioral
        self.behavioral_fadeout_started = False  # ×”×× ×”×ª×—×™×œ fade out

        # ×™×¦×™×¨×ª ××•×¤×¢×™× ×©×œ ×”××—×œ×§×•×ª ×”×—×“×©×•×ª
        self.text_renderer = TextRenderer()
        self.transition_manager = TransitionManager()
        self.prompt_generator = PromptGenerator()
        self.data_loader = DataLoader()

    def set_behavioral_data_saver(self, behavioral_data_saver):
        """×§×•×‘×¢ ×”×¤× ×™×” ×œ×©×•××¨ ×”× ×ª×•× ×™× ×”×”×ª× ×”×’×•×ª×™×™×"""
        self.behavioral_data_saver_ref = behavioral_data_saver

    def calculate_people_positions(self, active_persons):
        """××—×©×‘ ××ª ×”××™×§×•××™× ×”×™×—×¡×™×™× ×©×œ ×”×× ×©×™× ×‘××¡×š"""
        if not active_persons:
            return []

        positions = []
        num_people = len(active_persons)

        if num_people == 1:
            positions.append("×‘××¨×›×–")
        elif num_people == 2:
            positions = ["×‘×¦×“ ×™××™×Ÿ", "×‘×¦×“ ×©×××œ"]
        elif num_people == 3:
            positions = ["×‘×¦×“ ×™××™×Ÿ", "×‘××¨×›×–", "×‘×¦×“ ×©×××œ"]
        elif num_people == 4:
            positions = ["×‘×¦×“ ×™××™×Ÿ", "×‘×™×Ÿ ×™××™×Ÿ ×œ××¨×›×–", "×‘×™×Ÿ ××¨×›×– ×œ×©×××œ", "×‘×¦×“ ×©×××œ"]
        else:
            # ×™×•×ª×¨ ×-4 ×× ×©×™×
            for i in range(num_people):
                positions.append(f"××“× {i + 1}")

        return positions

    def update_prompt_opacity(self, current_time, has_people):
        """××¢×“×›×Ÿ ××ª ×©×§×™×¤×•×ª ×”×¤×¨×•××¤×˜ ×‘×”×ª×× ×œ××¦×‘ ×”×× ×©×™×"""
        if has_people:
            # ×™×© ×× ×©×™× - ×”×¤×¨×•××¤×˜ ×¦×¨×™×š ×œ×”×™×•×ª ××•×¦×’
            if not self.prompt_active:
                # ×”×ª×—×œ fade in
                if self.prompt_fade_in_start is None:
                    self.prompt_fade_in_start = current_time
                    self.prompt_fade_out_start = None  # ×‘×˜×œ fade out ×× ×”×™×”

                # ×—×©×‘ ×©×§×™×¤×•×ª fade in
                fade_in_elapsed = current_time - self.prompt_fade_in_start
                if fade_in_elapsed >= self.prompt_fade_in_duration:
                    self.prompt_opacity = 1.0
                    self.prompt_active = True
                    self.prompt_fade_in_start = None
                else:
                    self.prompt_opacity = fade_in_elapsed / self.prompt_fade_in_duration
            else:
                # ×”×¤×¨×•××¤×˜ ×›×‘×¨ ×¤×¢×™×œ
                self.prompt_opacity = 1.0
        else:
            # ××™×Ÿ ×× ×©×™× - ×”×¤×¨×•××¤×˜ ×¦×¨×™×š ×œ×”×™×¢×œ×
            if self.prompt_active:
                # ×”×ª×—×œ fade out
                if self.prompt_fade_out_start is None:
                    self.prompt_fade_out_start = current_time
                    self.prompt_fade_in_start = None  # ×‘×˜×œ fade in ×× ×”×™×”

                # ×—×©×‘ ×©×§×™×¤×•×ª fade out
                fade_out_elapsed = current_time - self.prompt_fade_out_start
                if fade_out_elapsed >= self.prompt_fade_out_duration:
                    self.prompt_opacity = 0.0
                    self.prompt_active = False
                    self.prompt_fade_out_start = None
                    # ××™×¤×•×¡ ×”×¤×¨×•××¤×˜
                    self.prompt_generated = False
                    self.prompt_display_index = 0
                    self.prompt_text = ""
                else:
                    self.prompt_opacity = 1.0 - (fade_out_elapsed / self.prompt_fade_out_duration)

    def toggle_grid(self):
        self.show_grid = not self.show_grid

    def toggle_timer(self):
        self.show_timer = not self.show_timer

    def toggle_info(self):
        self.show_info = not self.show_info

    def toggle_display_mode(self):
        """××—×œ×™×£ ×‘×™×Ÿ ×××’×¨ ×—×–×•×ª×™ ×œ×××’×¨ ×”×ª× ×”×’×•×ª×™ ×¢× ××¢×‘×¨ ×”×“×¨×’×ª×™"""
        print(f"ğŸ”„ MODE SWITCH: {self.display_mode} â†’ ", end="")

        if self.in_transition:
            print("(blocked - in transition)")
            return  # ××•× ×¢ ××¢×‘×¨ × ×•×¡×£ ×‘××”×œ×š ××¢×‘×¨ ×§×™×™×

        # ×œ××¦×‘ prompt - ×¢×‘×•×¨ ××—×¨×™ 15 ×©× ×™×•×ª
        elif self.display_mode == "prompt":
            current_time = time.time()
            self.mode_transition_time = current_time
            self.last_transition_step_time = current_time
            self.in_transition = True
            self.transition_stage = 0

        if self.display_mode == "visual":
            self.target_mode = "behavioral"
            print("behavioral")
            # ×”×›×Ÿ ×¨×©×™××ª ×˜×§×¡×˜×™× ×œ×”×¢×œ××” ××”×××’×¨ ×”×—×–×•×ª×™
            self.texts_to_fade_out = list(self.text_positions.keys()).copy()
            random.shuffle(self.texts_to_fade_out)  # ×¡×“×¨ ×¨× ×“×•××œ×™
        else:
            self.target_mode = "visual"
            print("visual")
            # ×”×›×Ÿ ×¨×©×™××ª ×˜×§×¡×˜×™× ×œ×”×¢×œ××” ××”×××’×¨ ×”×”×ª× ×”×’×•×ª×™
            self.texts_to_fade_out = list(self.behavioral_text_positions.keys()).copy()
            random.shuffle(self.texts_to_fade_out)  # ×¡×“×¨ ×¨× ×“×•××œ×™

        # ××™×¤×•×¡ ×”×˜×™×™××¨ ×”××•×˜×•××˜×™
        self.auto_mode_timer = current_time

    def toggle_json_overlay(self):
        self.show_json_overlay = not self.show_json_overlay
        print(f"ğŸ“Š OVERLAY: {'ON' if self.show_json_overlay else 'OFF'}")

    def _setup_screen_dimensions(self):
        monitor = get_monitors()[0]
        self.screen_width = monitor.width
        self.screen_height = monitor.height

    def setup_window(self):
        cv2.namedWindow(self.window_name, cv2.WINDOW_NORMAL)
        cv2.setWindowProperty(self.window_name, cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)

    def show_frame(self, frame, json_data_path, behavioral_data_path, active_persons=None):
        """×”×¦×’×ª ×¤×¨×™×™× ×¢× × ×ª×•× ×™ JSON ×•× ×ª×•× ×™× ×”×ª× ×”×’×•×ª×™×™×"""

        self.frame_count += 1

        # ğŸ” ×“×™×‘××’ - ××¢×§×‘ ××—×¨×™ ×©×™× ×•×™×™ ××¦×‘
        if self.frame_count % 30 == 0:  # ×›×œ ×©× ×™×™×” ×‘×¢×¨×š
            time_since_start = time.time() - self.app_start_time
            print(f"ğŸ­ ××¦×‘ × ×•×›×—×™: '{self.display_mode}' ×‘×©× ×™×” {int(time_since_start)}")

        # ×©××™×¨×ª ×¨×©×™××ª ×”×× ×©×™× ×”×¤×¢×™×œ×™×
        self.current_active_persons = active_persons if active_persons else []

        # ×©××™×¨×ª × ×ª×™×‘×™ ×”×§×‘×¦×™×
        self.visual_data_path = json_data_path
        self.behavioral_data_path = behavioral_data_path

        frame_height, frame_width, _ = frame.shape
        frame = cv2.flip(frame, 1)

        aspect_ratio_frame = frame_width / frame_height
        aspect_ratio_screen = self.screen_width / self.screen_height

        if aspect_ratio_frame > aspect_ratio_screen:
            new_width = self.screen_width
            new_height = int(new_width / aspect_ratio_frame)
        else:
            new_height = self.screen_height
            new_width = int(new_height * aspect_ratio_frame)

        resized_frame = cv2.resize(frame, (new_width, new_height), interpolation=cv2.INTER_AREA)

        full_screen_frame = np.zeros((self.screen_height, self.screen_width, 3), dtype=np.uint8)

        x_offset = (self.screen_width - new_width) // 2
        y_offset = (self.screen_height - new_height) // 2

        full_screen_frame[y_offset:y_offset + new_height,
        x_offset:x_offset + new_width] = resized_frame

        # --- ×”×•×¡×¤×ª ×©×›×‘×ª × ×ª×•× ×™ JSON ×× ×”×“×’×œ ×¤×¢×™×œ ---
        if self.show_json_overlay:
            black_screen = np.zeros((self.screen_height, self.screen_width, 3), dtype=np.uint8)

            # ×‘×“×™×§×ª ×˜×™×™××¨ ××•×˜×•××˜×™ ×œ××¢×‘×¨ ×‘×™×Ÿ ××¦×‘×™×
            current_time = time.time()

            # ×‘×“×™×§×ª ×˜×™×™××¨ ××•×˜×•××˜×™ ×œ××¢×‘×¨ ×‘×™×Ÿ ××¦×‘×™× ×× ×œ× ×‘××¢×‘×¨ ×›×¨×’×¢
            if not self.in_transition:
                # ×—×™×©×•×‘ ×–××Ÿ ××ª×—×™×œ×ª ×”×™×™×©×•×
                time_since_start = current_time - self.app_start_time

                # ×‘×“×™×§×” ×× ×™×© ×× ×©×™× ××•×œ ×”××¦×œ××”
                has_people = len(self.current_active_persons) > 0

                # ×¢×“×›×•×Ÿ ×©×§×™×¤×•×ª ×”×¤×¨×•××¤×˜
                self.update_prompt_opacity(current_time, has_people)

                # ×¢×“×›×•×Ÿ ××™×§×•××™ ×× ×©×™× ×× ×”×©×ª× ×”
                if len(self.current_active_persons) != self.last_people_count:
                    self.people_positions = self.calculate_people_positions(self.current_active_persons)
                    self.last_people_count = len(self.current_active_persons)
                    # ×× ×™×© ×× ×©×™× ×•×”×¤×¨×•××¤×˜ ×¤×¢×™×œ, ×¦×¨×™×š ×œ×¢×“×›×Ÿ ××•×ª×•
                    if has_people and self.prompt_active:
                        self.prompt_generated = False  # ×™×’×¨×•× ×œ×™×¦×™×¨×ª ×¤×¨×•××¤×˜ ×—×“×©

                # ×”×¤×¢×œ×ª behavioral mode ××—×¨×™ 30 ×©× ×™×•×ª
                if time_since_start >= self.behavioral_start_time and "behavioral_started" not in self.__dict__:
                    print(f"ğŸ”„ ××¢×‘×¨ ××•×˜×•××˜×™: ×”×¤×¢×œ×ª ××¦×‘ ×”×ª× ×”×’×•×ª×™ ×‘×©× ×™×” {int(time_since_start)}")
                    self.behavioral_started = True
                    # ×œ× ××©× ×™× ××ª display_mode - ×¨×§ ××•×¡×™×¤×™× ×˜×§×¡×˜×™× ×œ×‘× ×™×

                # ×”×ª×—×œ fade out ×©×œ ×˜×§×¡×˜×™× ×™×¨×•×§×™× ××—×¨×™ 25 ×©× ×™×•×ª
                if time_since_start >= self.visual_fadeout_start_time and not self.visual_fadeout_started:
                    print(f"ğŸŒ… ××ª×—×™×œ fade out ×©×œ ×˜×§×¡×˜×™× ×™×¨×•×§×™× ×‘×©× ×™×” {int(time_since_start)}")
                    self._start_visual_fadeout(current_time)
                    self.visual_fadeout_started = True

                # ğŸ” ×“×™×‘××’ - ×‘×“×™×§×ª ×ª× ××™ ×¤×¨×•××¤×˜ ×›×œ 5 ×©× ×™×•×ª
                if self.frame_count % 150 == 0:  # ×›×œ 5 ×©× ×™×•×ª ×‘×¢×¨×š
                    print(f"ğŸ” ×‘×“×™×§×ª ×¤×¨×•××¤×˜: ×¢×‘×¨ {int(time_since_start)} ×©× ×™×•×ª ××ª×—×™×œ×ª ×”×”×¨×¦×”")
                    print(
                        f"ğŸ” ×”×× ×¢×‘×¨×” ×“×§×”? {time_since_start >= self.prompt_start_time} (×¦×¨×™×š ×œ×¢×‘×•×¨ {self.prompt_start_time} ×©× ×™×•×ª)")
                    print(f"ğŸ” ××¦×‘ × ×•×›×—×™: '{self.display_mode}'")
                    print(f"ğŸ” ×”×× ×”××¦×‘ ×œ× ×¤×¨×•××¤×˜? {self.display_mode != 'prompt'}")
                    print(
                        f"ğŸ” ×©× ×™ ×”×ª× ××™× ××ª×§×™×™××™×? {time_since_start >= self.prompt_start_time and self.display_mode != 'prompt'}")
                    print("=" * 50)

                # ×”×¤×¢×œ×ª prompt mode ××—×¨×™ 60 ×©× ×™×•×ª (×“×§×”)
                if time_since_start >= self.prompt_start_time and self.display_mode != "prompt":
                    print(f"ğŸ¯ ××¢×‘×¨ ××•×˜×•××˜×™: ×¢×•×‘×¨ ×œ××¦×‘ ×¤×¨×•××¤×˜ ×‘×©× ×™×” {int(time_since_start)}")
                    self.display_mode = "prompt"
                    self.auto_mode_timer = current_time
                    self.prompt_generated = False
                    self.prompt_display_index = 0

                # ×œ××¦×‘ prompt - ×”×¦×’ ×¨×§ ×× ×™×© ×× ×©×™×
                if self.display_mode == "prompt":
                    if not has_people:
                        # ××™×Ÿ ×× ×©×™× - ×‘×“×•×§ ×× ×”×¤×¨×•××¤×˜ ×›×‘×¨ × ×¢×œ×
                        if self.prompt_opacity <= 0.0:
                            # ×”×¤×¨×•××¤×˜ × ×¢×œ× ×œ×’××¨×™ - × ×©××¨ ×‘××¦×‘ prompt ××‘×œ ×œ× ××¦×™×’
                            pass
                        # ××—×¨×ª - ×”×¤×¨×•××¤×˜ ×¢×“×™×™×Ÿ ×‘×ª×”×œ×™×š fade out
                    else:
                        # ×™×© ×× ×©×™× - ×”×¤×¨×•××¤×˜ × ×©××¨ ××•×¦×’
                        # ×•×•×“× ×©×”×¤×¨×•××¤×˜ ×¤×¢×™×œ
                        if not self.prompt_active:
                            self.prompt_active = True
                            self.prompt_opacity = 1.0

            # ×¢×™×‘×•×“ ××¢×‘×¨ ×”×“×¨×’×ª×™
            self.transition_manager.process_gradual_transition(self, current_time)

            if self.display_mode == "visual" and not self.in_transition:
                # ×”×¦×’ ×˜×§×¡×˜×™× ×™×¨×•×§×™× ×¨×§ ×¢×“ ×©× ×™×” 30
                time_since_start = current_time - self.app_start_time
                if time_since_start < 30:  # ×¨×§ ×‘-30 ×”×©× ×™×•×ª ×”×¨××©×•× ×•×ª
                    data_lines = self.data_loader.get_visual_data_lines(json_data_path)
                    self._display_visual_texts(black_screen, data_lines)
                else:
                    # ××—×¨×™ 30 ×©× ×™×•×ª - ×¨×§ ×¦×™×™×¨ ××ª ×”×§×™×™××™×, ××œ ×ª×•×¡×™×£ ×—×“×©×™×
                    pil_image = Image.fromarray(cv2.cvtColor(black_screen, cv2.COLOR_BGR2RGB))
                    draw = ImageDraw.Draw(pil_image)
                    try:
                        font_base = ImageFont.load_default()
                    except:
                        font_base = None
                    self.text_renderer.draw_texts(self, draw, font_base, current_time, self.text_positions,
                                                  is_behavioral=False)
                    black_screen[:] = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)

                # ×”×•×¡×£ ×’× ×˜×§×¡×˜×™× ×œ×‘× ×™× ×× ×”×“×’×œ ××•×¤×¢×œ
                if hasattr(self, 'behavioral_started') and self.behavioral_started:
                    # ×¦×™×™×¨ ×˜×§×¡×˜×™× ×œ×‘× ×™× ×¢×œ ××•×ª×• ××¡×š
                    pil_image = Image.fromarray(cv2.cvtColor(black_screen, cv2.COLOR_BGR2RGB))
                    draw = ImageDraw.Draw(pil_image)
                    try:
                        font_base = ImageFont.load_default()
                    except:
                        font_base = None

                    # ×¦×™×™×¨ ××ª ×”×˜×§×¡×˜×™× ×”×œ×‘× ×™×
                    current_time = time.time()
                    self.text_renderer.draw_texts(self, draw, font_base, current_time,
                                                  self.behavioral_text_positions, is_behavioral=True)

                    # ×”×—×–×¨ ×œ-OpenCV
                    black_screen[:] = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)

            elif self.display_mode == "behavioral" and not self.in_transition:
                data_lines = self.data_loader.get_behavioral_data_lines(self, behavioral_data_path)
                self._display_behavioral_texts(black_screen, data_lines)

            elif self.display_mode == "prompt":
                print(f"ğŸ¬ ××¦×™×’ ×¤×¨×•××¤×˜: has_people={has_people}, opacity={self.prompt_opacity:.2f}")

                # ×”×¦×’×ª ×”×¤×¨×•××¤×˜ ×¢× ××¤×§×˜ ×”×§×œ×“×”
                self.prompt_generator.display_prompt_with_typewriter(self, black_screen, current_time)
            elif self.in_transition:
                # ×‘××”×œ×š ××¢×‘×¨ - ×”×¦×’ ××ª ×©× ×™ ×”×¡×•×’×™× ×¢× fade out/in
                self.transition_manager.display_transition_texts(self, black_screen, json_data_path,
                                                                 behavioral_data_path)

            full_screen_frame = black_screen

        # ×”×¦×’×ª ×’×¨×™×“ ×× ××•×¤×¢×œ
        if self.show_grid:
            cell_width = self.screen_width // self.grid_cols
            cell_height = self.screen_height // self.grid_rows

            for i in range(1, self.grid_cols):
                x = i * cell_width
                cv2.line(full_screen_frame, (x, 0), (x, self.screen_height), (50, 50, 50), 1)

            for i in range(1, self.grid_rows):
                y = i * cell_height
                cv2.line(full_screen_frame, (0, y), (self.screen_width, y), (50, 50, 50), 1)

        # ×”×¦×’×ª ×˜×™×™××¨
        if self.show_timer:
            elapsed = time.time() - self.start_time
            minutes = int(elapsed // 60)
            seconds = int(elapsed % 60)
            timer_text = f"{minutes:02d}:{seconds:02d}"
            cv2.putText(full_screen_frame, timer_text, (self.screen_width - 150, 50),
                        cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 2)

        # ×”×¦×’×ª ××™×“×¢
        if self.show_info:
            info_lines = []

            # ×§×‘×œ ××™×“×¢ ×¢×œ ×”×¡×¦× ×” ×”× ×•×›×—×™×ª
            current_scene_id = "001"  # ×‘×¨×™×¨×ª ××—×“×œ

            # ×§×¨× ××ª ×”× ×ª×•× ×™× ××”×§×•×‘×¥
            if os.path.exists(json_data_path):
                try:
                    with open(json_data_path, 'r', encoding='utf-8') as f:
                        json_data = json.load(f)
                        sessions = json_data.get("sessions", [])
                        if sessions:
                            latest_session = sessions[-1]
                            current_scene_id = latest_session.get("session_id", "001")
                except:
                    pass

            # ×”×•×¡×£ ××ª ×”××™×“×¢ ×œ×ª×¦×•×’×”
            info_lines.append(f"Scene: {current_scene_id}")

            # ××¡×¤×¨ ×× ×©×™× ×¤×¢×™×œ×™×
            if hasattr(self, 'current_active_persons') and self.current_active_persons:
                info_lines.append(f"Persons in frame: {len(self.current_active_persons)}")
                person_ids_str = ", ".join([str(pid) for pid in self.current_active_persons])
                info_lines.append(f"Person IDs: {person_ids_str}")
            else:
                info_lines.append(f"Persons in frame: 0")

            # ×”×•×¡×£ ××™×“×¢ ×¢×œ ×”××¦×‘ ×”× ×•×›×—×™ ×•×”×–××Ÿ ××ª×—×™×œ×ª ×”×™×™×©×•×
            time_since_start = current_time - self.app_start_time
            info_lines.append(f"Mode: {self.display_mode}")
            info_lines.append(f"Time since start: {int(time_since_start)}s")

            # ×”×¦×’ ×‘××™×–×” ×©×œ×‘×™× ×× ×—× ×•
            if hasattr(self, 'behavioral_started') and self.behavioral_started:
                info_lines.append("Behavioral: Active")

            # ×”×¦×’ ××ª ×”××™×“×¢
            y_offset = 100
            for line in info_lines:
                # ×¨×§×¢ ×©×—×•×¨ ×××—×•×¨×™ ×”×˜×§×¡×˜
                text_size = cv2.getTextSize(line, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 1)[0]
                cv2.rectangle(full_screen_frame,
                              (self.screen_width - 350, y_offset - 25),
                              (self.screen_width - 350 + text_size[0] + 10, y_offset + 5),
                              (0, 0, 0), -1)

                # ×”×˜×§×¡×˜ ×¢×¦××•
                cv2.putText(full_screen_frame, line, (self.screen_width - 340, y_offset),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 1)
                y_offset += 35

        # --- × ×”×œ ××—×–×•×¨ ×˜×§×¡×˜×™× ×”×ª× ×”×’×•×ª×™×™× ×ª××™×“ ---
        if self.show_json_overlay and hasattr(self, 'behavioral_started') and self.behavioral_started:
            current_time = time.time()
            # ×§×‘×œ × ×ª×•× ×™× ×–××™× ×™×
            available_data = []
            if self.behavioral_data_saver_ref:
                available_data = self.behavioral_data_saver_ref.get_persistent_insights()

            # × ×”×œ ××ª ×”××—×–×•×¨
            self._manage_behavioral_cycle(current_time, available_data)

        cv2.imshow(self.window_name, full_screen_frame)


    def _get_visual_data_lines(self, json_data_path):
        """×§×‘×œ×ª × ×ª×•× ×™× ×—×–×•×ª×™×™× ××”×××’×¨ ×”×¨××©×•×Ÿ"""
        return self.data_loader.get_visual_data_lines(json_data_path)

    def _get_behavioral_data_lines(self, behavioral_data_path):
        """×§×‘×œ×ª × ×ª×•× ×™× ×”×ª× ×”×’×•×ª×™×™× ××”×××’×¨ ×”×©× ×™"""
        return self.data_loader.get_behavioral_data_lines(self, behavioral_data_path)

    def _display_visual_texts(self, black_screen, data_lines):
        """×”×¦×’×ª ×˜×§×¡×˜×™× ×—×–×•×ª×™×™× (×”×××’×¨ ×”×¨××©×•×Ÿ)"""
        pil_image = Image.fromarray(cv2.cvtColor(black_screen, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(pil_image)

        current_time = time.time()

        try:
            font_base = ImageFont.load_default()
        except:
            font_base = None

        # × ×§×” ×˜×§×¡×˜×™× ×©×¤×’ ×–×× ×
        self.text_renderer.cleanup_expired_texts(self, current_time, self.text_positions, self.occupied_cells,
                                                 self.cell_last_used,
                                                 is_behavioral=False)

        # ×”×•×¡×£ ×˜×§×¡×˜×™× ×—×“×©×™× ××• ×¢×“×›×Ÿ ×§×™×™××™×
        for line in data_lines:
            if line.strip():
                line_key = line.strip()
                if line_key not in self.text_positions:
                    self.text_renderer.add_new_text(self, line_key, current_time, self.text_positions,
                                                    self.occupied_cells,
                                                    self.cell_last_used, is_behavioral=False)

        # ×¦×™×™×¨ ××ª ×›×œ ×”×˜×§×¡×˜×™× ×¢× ×¦×‘×¢×™× ×©×œ ×”×××’×¨ ×”×¨××©×•×Ÿ
        self.text_renderer.draw_texts(self, draw, font_base, current_time, self.text_positions, is_behavioral=False)

        # ×”××¨×” ×—×–×¨×” ×œ-OpenCV
        black_screen[:] = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)

    def _display_behavioral_texts(self, black_screen, data_lines):
        """×”×¦×’×ª ×˜×§×¡×˜×™× ×”×ª× ×”×’×•×ª×™×™× (×”×××’×¨ ×”×©× ×™)"""
        pil_image = Image.fromarray(cv2.cvtColor(black_screen, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(pil_image)

        current_time = time.time()

        try:
            font_base = ImageFont.load_default()
        except:
            font_base = None

        # × ×§×” ×˜×§×¡×˜×™× ×©×¤×’ ×–×× ×
        self.text_renderer.cleanup_expired_texts(self, current_time, self.behavioral_text_positions,
                                                 self.behavioral_occupied_cells, self.behavioral_cell_last_used,
                                                 is_behavioral=True)

        # ×¢×“×›×Ÿ ××ª ×”×××’×¨ ×× ×™×© × ×ª×•× ×™× ×—×“×©×™×
        if data_lines and len(data_lines) > len(self.behavioral_texts_pool):
            self.behavioral_texts_pool = [line.strip() for line in data_lines if line.strip()]

        # ×¦×™×™×¨ ××ª ×›×œ ×”×˜×§×¡×˜×™× ×¢× ×¦×‘×¢ ×œ×‘×Ÿ
        self.text_renderer.draw_texts(self, draw, font_base, current_time, self.behavioral_text_positions,
                                      is_behavioral=True)

        # ×”××¨×” ×—×–×¨×” ×œ-OpenCV
        black_screen[:] = cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)

    def _start_behavioral_fadeout(self, current_time):
        """××ª×—×™×œ fade out ×œ×›×œ ×”××©×¤×˜×™× ×”×œ×‘× ×™×"""
        for text_key in self.behavioral_text_positions:
            if 'fade_out_start' not in self.behavioral_text_positions[text_key]:
                self.behavioral_text_positions[text_key]['fade_out_start'] = current_time
                self.behavioral_text_positions[text_key]['fade_out_duration'] = 2.0  # 2 ×©× ×™×•×ª fade out
        print(f"ğŸŒ… Starting fade out for {len(self.behavioral_text_positions)} behavioral texts")

    def _start_visual_fadeout(self, current_time):
        """××ª×—×™×œ fade out ×œ×›×œ ×”××™×œ×™× ×”×™×¨×•×§×•×ª ×‘×–×• ××—×¨ ×–×•"""
        text_keys = list(self.text_positions.keys())
        random.shuffle(text_keys)  # ×¡×“×¨ ×¨× ×“×•××œ×™

        for i, text_key in enumerate(text_keys):
            if text_key in self.text_positions and 'fade_out_start' not in self.text_positions[text_key]:
                # ×›×œ ××™×œ×” ××ª×—×™×œ×” fade out ×¢× ×”×¤×¨×© ×©×œ 0.5 ×©× ×™×•×ª
                self.text_positions[text_key]['fade_out_start'] = current_time + (i * 0.5)
                self.text_positions[text_key]['fade_out_duration'] = 2.0  # 2 ×©× ×™×•×ª fade out

        print(f"ğŸŒ… Starting fade out for {len(text_keys)} visual texts")

    def _manage_behavioral_cycle(self, current_time, data_lines):
        """×× ×”×œ ××—×–×•×¨ ×©×œ ×˜×§×¡×˜×™× ×”×ª× ×”×’×•×ª×™×™×"""
        if not self.behavioral_cycle_enabled:
            return

        # ×¢×“×›×Ÿ ××ª ×××’×¨ ×”×˜×§×¡×˜×™× ××”× ×ª×•× ×™× ×”×–××™× ×™×
        if data_lines and len(data_lines) > 0:
            quality_texts = [line.strip() for line in data_lines if line.strip() and len(line.strip()) > 5]
            if len(quality_texts) > len(self.behavioral_texts_pool):
                self.behavioral_texts_pool = quality_texts
                print(f"ğŸ“ POOL UPDATED: {len(self.behavioral_texts_pool)} texts")

        # ×× ××™×Ÿ ×××’×¨ ×˜×§×¡×˜×™× - × ×¡×” ×œ×˜×¢×•×Ÿ ××”×§×•×‘×¥
        if not self.behavioral_texts_pool and self.behavioral_data_saver_ref:
            available_insights = self.behavioral_data_saver_ref.get_persistent_insights()
            if available_insights:
                self.behavioral_texts_pool = available_insights
                print(f"ğŸ“ POOL LOADED: {len(self.behavioral_texts_pool)} texts from cache")

        # ×¡×¤×•×¨ ×˜×§×¡×˜×™× ×¤×¢×™×œ×™×
        active_count = len(self.behavioral_text_positions)

        # ×ª× ××™× ×œ×”×•×¡×¤×ª ×˜×§×¡×˜ ×—×“×©
        time_since_last_add = current_time - self.last_behavioral_text_add

        # ×”×•×¡×£ ××©×¤×˜ ×—×“×© ×›×œ ×©× ×™×™×”
        add_interval = 1.0

        should_add_text = False

        # ××™×Ÿ ×˜×§×¡×˜×™× ×¤×¢×™×œ×™× - ×”×•×¡×£ ××™×“
        if active_count == 0 and self.behavioral_texts_pool and self.behavioral_pool_index < len(
                self.behavioral_texts_pool):
            should_add_text = True
            print("ğŸš€ NO ACTIVE TEXTS - Adding immediately")

        # ×”×•×¡×£ ×¢×“ ×©× ×’××¨ ×”×××’×¨
        elif (time_since_last_add >= add_interval and
              self.behavioral_texts_pool and
              self.behavioral_pool_index < len(self.behavioral_texts_pool)):
            should_add_text = True
            print(f"âš¡ ADDING TEXT ({self.behavioral_pool_index + 1}/{len(self.behavioral_texts_pool)})")

        if should_add_text:
            # ×§×— ×˜×§×¡×˜ ×—×“×©
            if self.behavioral_pool_index < len(self.behavioral_texts_pool):
                text_to_add = self.behavioral_texts_pool[self.behavioral_pool_index]

                if text_to_add not in self.behavioral_text_positions:
                    # ×–××Ÿ ×—×™×™× ×©×œ 8 ×©× ×™×•×ª ×‘×“×™×•×§
                    lifetime = 12.0

                    self.text_renderer.add_new_text_with_lifetime(self, text_to_add, current_time, lifetime,
                                                                  self.behavioral_text_positions,
                                                                  self.behavioral_occupied_cells,
                                                                  self.behavioral_cell_last_used,
                                                                  is_behavioral=True)
                    self.last_behavioral_text_add = current_time
                    self.behavioral_pool_index += 1
                    print(f"â• ADD TEXT #{self.behavioral_pool_index} (active: {active_count + 1})")
                else:
                    self.behavioral_pool_index += 1